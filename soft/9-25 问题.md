# 9-25 问题

## MAML

![image-20220925200131472](C:\Users\Yu.Y\AppData\Roaming\Typora\typora-user-images\image-20220925200131472.png)

我的理解是，learning to learn 试图提高模型在不同任务中的泛化能力，相当于将任务当成了样本，让网络的loss在“任务测试集”上达到最低，这样在面对**新的任务**（*此处是否要求新任务中的class是没有出现过的？还是说是在$p(T)$中新生成的task？我觉得应该是后者吧*）时，此网络可以在很少的样本下快速finetune，适应任务。

训练的方法是用两重的循环。每个task中包含support set 和 query set 对应 任务训练集和任务测试集（*验证集是否存在？是包含在support set当中吗？每个task中的样本数应该不少吧，内层的训练应该就是普通的训练？*），通过内层的训练对网络参数进行第一次的更新。

所有的task都跑完内循环以后，来到外循环。把更新过的网络在所有task 的Query Set上面test，计算所有task的loss的和，并基于此进行梯度下降对**原始网络参数**进行正式的更新。（*为什么不直接对$\theta'$ 进行更新呢？是因为会$\theta'$过度偏向于这一次循环中的那些任务吗？*）

还有一个问题是，内循环和外循环都是对本次抽取的的所有tasks分别进行support set和query set的遍历，感觉模糊了task内部的结构特征，即task中有多少类有多少样本都不重要了，反正是一起算的。那为什么不直接抽取等量的sample直接进行训练，再用等量的sample去test去梯度下降呢？感觉从算法上说这是等价的？



## ProtoNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200318111855496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwMTQ2OTM3,size_16,color_FFFFFF,t_70)

我的理解是，MAML是用元学习去进行小样本学习， 而ProtoNet是用embedding learning去进行小样本学习。ProtoNet具有把一个sample快速embed到一个“原型空间”的能力，其实是提取出了里面可以用于分类的关键特征。

这里的训练方法也有support set 和query set，但感觉与MAML中的完全不同。此处的support set 和query set 基于class来区分，而不是task，support set 只是用于计算出原型$c_k$的位置，不用于训练。训练在$Q_k$中进行，观察损失函数感觉训练的最终目的是让属于此类的样本尽可能接近原型而不属于此类的样本尽可能远离原型。

最后通过梯度下降法去更新$f_\phi$中的权重。

问题是$f_\phi$的初始结构是如何确定的？参数太少不足以描述特征，参数太多小样本学习难以实现，怎样知道$f_\phi$能否很好地提取出特征？从数学上理解，我感觉这种“万物皆有原型”的假设是不大靠谱的。

以及最终应用ProtoNet的时候是把一个未参与过训练的但与其他类相似的类丢进去让它输出一个原型用于分类吗？